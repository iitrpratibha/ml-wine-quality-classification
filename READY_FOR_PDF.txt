════════════════════════════════════════════════════════════════════════
                            BITS PILANI
                Work Integrated Learning Programmes
                      M.Tech (AIML / DSE)

                       MACHINE LEARNING
                        ASSIGNMENT - 2
════════════════════════════════════════════════════════════════════════

Student Name:    [YOUR FULL NAME HERE]

Student ID:      [YOUR STUDENT ID HERE]

Program:         M.Tech (AIML/DSE)

Subject:         Machine Learning

Assignment:      Assignment 2

Total Marks:     15

Submission Date: 15-February-2026


════════════════════════════════════════════════════════════════════════
                         SUBMISSION LINKS
════════════════════════════════════════════════════════════════════════

1. GITHUB REPOSITORY LINK

   https://github.com/iitrpratibha/ml-wine-quality-classification


2. LIVE STREAMLIT APP LINK

   https://ml-wine-quality-classification-rddwem3ymumeq73kuysrpc.streamlit.app/


3. REPOSITORY CONTENTS

   ✓ Complete source code (app.py, train_models.py, data preparation scripts)
   ✓ requirements.txt with all dependencies
   ✓ README.md with comprehensive documentation
   ✓ All 6 trained ML models (.pkl files)
   ✓ Dataset files (Wine Quality Dataset)
   ✓ Model evaluation results (JSON and CSV)


════════════════════════════════════════════════════════════════════════
                    BITS VIRTUAL LAB SCREENSHOT
════════════════════════════════════════════════════════════════════════

[INSERT YOUR BITS LAB SCREENSHOT HERE]

Screenshot shows:
- BITS Virtual Lab environment
- Commands executed (git clone, model training)
- Successful execution output
- Verification of all components


════════════════════════════════════════════════════════════════════════
                         PROJECT DOCUMENTATION
════════════════════════════════════════════════════════════════════════


WINE QUALITY CLASSIFICATION - ML ASSIGNMENT 2


PROBLEM STATEMENT

The objective of this project is to build and compare multiple machine
learning classification models to predict wine quality. The task involves
classifying wines into two categories: Good Quality (quality rating ≥ 7)
and Not Good Quality (quality rating < 7) based on various physicochemical
properties of wine.

This is a binary classification problem that helps wine producers and
quality control teams to:
• Predict wine quality based on measurable chemical properties
• Understand which factors contribute most to wine quality
• Automate quality assessment processes
• Compare the performance of different machine learning algorithms


DATASET DESCRIPTION

Dataset Information:
• Source: UCI Machine Learning Repository - Wine Quality Dataset
• Total Instances: 6,497 samples
  - Red Wine: 1,599 samples
  - White Wine: 4,898 samples
• Total Features: 12 features
• Target Variable: Binary classification
  - Class 0 (Not Good): 5,220 samples (80.34%)
  - Class 1 (Good Quality): 1,277 samples (19.66%)
• Missing Values: None

Features Description:

The dataset contains the following 12 features:

1. fixed acidity: Fixed acids in wine (tartaric acid - g/dm³)
2. volatile acidity: Volatile acids in wine (acetic acid - g/dm³)
3. citric acid: Citric acid content (g/dm³)
4. residual sugar: Remaining sugar after fermentation (g/dm³)
5. chlorides: Salt content in wine (sodium chloride - g/dm³)
6. free sulfur dioxide: Free form of SO₂ (mg/dm³)
7. total sulfur dioxide: Total SO₂ content (mg/dm³)
8. density: Density of wine (g/cm³)
9. pH: Acidity level (0-14 scale)
10. sulphates: Wine additive (potassium sulphate - g/dm³)
11. alcohol: Alcohol content (% by volume)
12. wine_type: Type of wine (1 = Red, 0 = White)

Data Split:
• Training Set: 80% (5,197 samples)
• Test Set: 20% (1,300 samples)
• Stratification: Applied to maintain class distribution


MODELS USED

Model Comparison Table:

┌─────────────────────────┬──────────┬────────┬───────────┬────────┬────────┬────────┐
│ ML Model Name           │ Accuracy │ AUC    │ Precision │ Recall │ F1     │ MCC    │
├─────────────────────────┼──────────┼────────┼───────────┼────────┼────────┼────────┤
│ Logistic Regression     │ 0.8223   │ 0.8048 │ 0.6147    │ 0.2617 │ 0.3671 │ 0.3178 │
├─────────────────────────┼──────────┼────────┼───────────┼────────┼────────┼────────┤
│ Decision Tree           │ 0.8538   │ 0.7749 │ 0.6250    │ 0.6445 │ 0.6346 │ 0.5434 │
├─────────────────────────┼──────────┼────────┼───────────┼────────┼────────┼────────┤
│ kNN                     │ 0.8323   │ 0.8264 │ 0.5922    │ 0.4766 │ 0.5281 │ 0.4314 │
├─────────────────────────┼──────────┼────────┼───────────┼────────┼────────┼────────┤
│ Naive Bayes             │ 0.7346   │ 0.7486 │ 0.3901    │ 0.6172 │ 0.4781 │ 0.3268 │
├─────────────────────────┼──────────┼────────┼───────────┼────────┼────────┼────────┤
│ Random Forest           │ 0.8869   │ 0.9123 │ 0.8079    │ 0.5586 │ 0.6605 │ 0.6100 │
│ (Ensemble)              │          │        │           │        │        │        │
├─────────────────────────┼──────────┼────────┼───────────┼────────┼────────┼────────┤
│ XGBoost                 │ 0.8792   │ 0.9021 │ 0.7281    │ 0.6172 │ 0.6681 │ 0.5979 │
│ (Ensemble)              │          │        │           │        │        │        │
└─────────────────────────┴──────────┴────────┴───────────┴────────┴────────┴────────┘


MODEL PERFORMANCE OBSERVATIONS

┌─────────────────────────┬────────────────────────────────────────────────────┐
│ ML Model Name           │ Observation about model performance                │
├─────────────────────────┼────────────────────────────────────────────────────┤
│ Logistic Regression     │ Achieved good accuracy (82.23%) and decent AUC    │
│                         │ (80.48%), demonstrating solid linear separability │
│                         │ in the data. However, it suffers from low recall  │
│                         │ (26.17%), indicating it misses many positive cases│
│                         │ (good quality wines). The model is conservative in│
│                         │ predicting the positive class, leading to high    │
│                         │ precision but low sensitivity. Best suited when   │
│                         │ false positives are more costly than false        │
│                         │ negatives.                                         │
├─────────────────────────┼────────────────────────────────────────────────────┤
│ Decision Tree           │ Showed strong balanced performance with accuracy  │
│                         │ of 85.38% and the highest recall among all models │
│                         │ (64.45%). The model effectively captures non-     │
│                         │ linear relationships in the data without requiring│
│                         │ feature scaling. However, it has a lower AUC      │
│                         │ (77.49%) compared to ensemble methods, suggesting │
│                         │ potential overfitting to training data. The       │
│                         │ balanced F1 score (63.46%) indicates good trade-  │
│                         │ off between precision and recall.                 │
├─────────────────────────┼────────────────────────────────────────────────────┤
│ kNN                     │ Demonstrated good AUC score (82.64%) with moderate│
│                         │ accuracy (83.23%), indicating strong probabilistic│
│                         │ ranking ability. The model's performance is       │
│                         │ sensitive to the choice of k (set to 5) and       │
│                         │ distance metric. Recall is moderate (47.66%),     │
│                         │ suggesting it struggles with minority class       │
│                         │ detection. Feature scaling significantly impacts  │
│                         │ kNN performance, making preprocessing crucial.    │
│                         │ Computational cost increases with dataset size.   │
├─────────────────────────┼────────────────────────────────────────────────────┤
│ Naive Bayes             │ Showed the lowest accuracy (73.46%) among all     │
│                         │ models, likely due to violation of the            │
│                         │ independence assumption between features in wine  │
│                         │ chemistry. However, it achieved the second-highest│
│                         │ recall (61.72%), making it useful when detecting  │
│                         │ positive cases is important. The model is fast to │
│                         │ train and requires minimal hyperparameter tuning. │
│                         │ Low precision (39.01%) indicates high false       │
│                         │ positive rate, limiting practical applicability   │
│                         │ for quality control.                              │
├─────────────────────────┼────────────────────────────────────────────────────┤
│ Random Forest           │ Emerged as the best overall performer with highest│
│ (Ensemble)              │ accuracy (88.69%), AUC (91.23%), precision        │
│                         │ (80.79%), and MCC (61.00%). The ensemble approach │
│                         │ effectively reduces overfitting while capturing   │
│                         │ complex non-linear patterns. High precision       │
│                         │ indicates strong reliability when predicting good │
│                         │ quality wines. Moderate recall (55.86%) suggests  │
│                         │ room for improvement in detecting all positive    │
│                         │ cases. Feature importance analysis reveals alcohol│
│                         │ content and volatile acidity as top predictors.   │
├─────────────────────────┼────────────────────────────────────────────────────┤
│ XGBoost                 │ Achieved excellent performance with second-best   │
│ (Ensemble)              │ accuracy (87.92%) and highest F1 score (66.81%),  │
│                         │ indicating the best balance between precision and │
│                         │ recall. Strong AUC (90.21%) demonstrates superior │
│                         │ ranking capability. The gradient boosting approach│
│                         │ handles imbalanced data well. Better recall       │
│                         │ (61.72%) than Random Forest makes it more suitable│
│                         │ when detecting good wines is prioritized.         │
│                         │ Requires careful hyperparameter tuning but offers │
│                         │ state-of-the-art performance for this             │
│                         │ classification task.                              │
└─────────────────────────┴────────────────────────────────────────────────────┘


KEY INSIGHTS

1. Ensemble Methods Dominate: Random Forest and XGBoost significantly
   outperform individual classifiers, demonstrating the power of ensemble
   learning.

2. Class Imbalance Impact: The dataset has ~80% negative class, which
   affects model behavior. Models like Logistic Regression are conservative,
   while Naive Bayes and XGBoost handle imbalance better.

3. Precision vs Recall Trade-off:
   • High precision models (Random Forest, XGBoost): Better for quality
     assurance scenarios
   • High recall models (Decision Tree, Naive Bayes): Better for not missing
     good quality wines

4. Feature Engineering Importance: Feature scaling significantly impacts
   models like kNN and Logistic Regression, while tree-based methods are
   scale-invariant.

5. Production Recommendation: Random Forest or XGBoost are recommended for
   deployment due to their superior overall performance and robustness.


TECHNICAL IMPLEMENTATION

Libraries Used:
• pandas: Data manipulation and analysis
• numpy: Numerical computations
• scikit-learn: Machine learning algorithms and metrics
• xgboost: Gradient boosting implementation
• matplotlib & seaborn: Data visualization
• streamlit: Web application framework
• joblib: Model serialization

Model Training Pipeline:
1. Data loading and exploration
2. Train-test split (80-20) with stratification
3. Feature scaling using StandardScaler
4. Model training on scaled features
5. Comprehensive evaluation using 6 metrics
6. Model persistence using joblib

Evaluation Metrics:
• Accuracy: Overall correctness of predictions
• AUC: Area Under ROC Curve - discrimination capability
• Precision: Correctness of positive predictions
• Recall: Coverage of actual positive cases
• F1 Score: Harmonic mean of precision and recall
• MCC: Matthews Correlation Coefficient - balanced measure for imbalanced data


STREAMLIT WEB APPLICATION

Features Implemented:

1. Dataset Upload Option (CSV)
   • File upload functionality for test data
   • Automatic data validation
   • Preview of uploaded data
   • Supports wine quality predictions

2. Model Selection Dropdown
   • All 6 models available for selection
   • Easy switching between different algorithms
   • Default selection: Random Forest (best performer)
   • Clear model descriptions

3. Evaluation Metrics Display
   • Accuracy, Precision, Recall, F1 Score
   • Interactive metric cards
   • Color-coded performance indicators
   • Comparison with other models

4. Confusion Matrix & Classification Report
   • Visual confusion matrix heatmap
   • Detailed classification report
   • True/False Positive/Negative counts
   • Per-class precision, recall, and F1 scores

Additional Features:
• Home page with project overview
• Interactive model comparison dashboard
• Bar charts and heatmaps for visualization
• Dataset information and statistics page
• Downloadable prediction results
• Professional UI design

Live Application URL:
https://ml-wine-quality-classification-rddwem3ymumeq73kuysrpc.streamlit.app/

Status: Successfully deployed and accessible


REPOSITORY STRUCTURE

ml-wine-quality-classification/
│
├── app.py                           # Streamlit web application
├── requirements.txt                 # Python dependencies
├── README.md                        # Project documentation
│
├── data/
│   ├── winequality-red.csv          # Red wine data (1,599 samples)
│   ├── winequality-white.csv        # White wine data (4,898 samples)
│   └── wine_quality_prepared.csv    # Processed dataset
│
└── model/
    ├── train_models.py              # Model training script
    ├── prepare_wine_data.py         # Data preparation script
    ├── logistic_regression.pkl      # Trained models
    ├── decision_tree.pkl
    ├── knn.pkl
    ├── naive_bayes.pkl
    ├── random_forest.pkl
    ├── xgboost.pkl
    ├── scaler.pkl                   # Feature scaler
    ├── results.json                 # Evaluation results
    └── results.csv


HOW TO RUN LOCALLY

1. Clone Repository
   git clone https://github.com/iitrpratibha/ml-wine-quality-classification.git
   cd ml-wine-quality-classification

2. Create Virtual Environment
   python3 -m venv venv
   source venv/bin/activate

3. Install Dependencies
   pip install -r requirements.txt

4. Train Models (Optional - already trained)
   python model/train_models.py

5. Run Streamlit App
   streamlit run app.py

The app will open in your browser at http://localhost:8501


CONCLUSION

This project successfully demonstrates:

1. Data Processing: Effective handling of real-world wine quality data
2. Model Diversity: Implementation of 6 different ML algorithms
3. Comprehensive Evaluation: Multi-metric assessment for fair comparison
4. Ensemble Superiority: Random Forest and XGBoost outperform individual
   classifiers
5. Production-Ready: Interactive web application for practical deployment
6. Documentation: Complete technical and user documentation

The Random Forest model is recommended for production use, achieving 88.69%
accuracy with excellent precision (80.79%) and the highest AUC (91.23%),
making it reliable for wine quality prediction.


REFERENCES

1. P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine
   preferences by data mining from physicochemical properties. Decision
   Support Systems, Elsevier, 47(4):547-553, 2009.

2. UCI Machine Learning Repository: Wine Quality Dataset
   https://archive.ics.uci.edu/ml/datasets/wine+quality

3. Scikit-learn Documentation: https://scikit-learn.org/
4. XGBoost Documentation: https://xgboost.readthedocs.io/
5. Streamlit Documentation: https://docs.streamlit.io/


ACADEMIC INTEGRITY STATEMENT

This project has been completed in accordance with BITS Pilani's academic
integrity guidelines. All code has been written originally for this
assignment. External libraries and datasets are properly cited. The work
represents genuine effort in understanding and implementing machine learning
concepts.


════════════════════════════════════════════════════════════════════════
                          END OF SUBMISSION
════════════════════════════════════════════════════════════════════════

Student Name: [YOUR NAME]
Student ID:   [YOUR ID]
Date:         15-February-2026

Total Pages: [Number based on your formatting]
Status: Ready for Submission
